{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import pandas as pd\n",
    "import torchtext\n",
    "import math\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import csv\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, root='train.csv'):\n",
    "\n",
    "        self.data=pd.read_csv(root)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        #id = row['id']\n",
    "        label = row['category']-1\n",
    "        headline = str(row['headline'])\n",
    "        short_description = str(row['short_description'])\n",
    "        text=str(headline+' '+short_description)\n",
    "        text=text.replace('“','').replace('‘','').replace('”','')\n",
    "        return label,text\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root='test.csv'):\n",
    "\n",
    "        self.data=pd.read_csv(root)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        #id = row['id']\n",
    "        #label = row['category']\n",
    "        headline = str(row['headline'])\n",
    "        short_description = str(row['short_description'])\n",
    "        text=str(headline+' '+short_description)\n",
    "        text=text.replace('“','').replace('‘','').replace('”','')\n",
    "        return 0,text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Data Preprocessing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "選擇tokenzier需要考慮data語言、詞彙大小、上下文、特殊字符和模型等因素\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以使用空白鍵來做tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['analysts',\n",
       " 'predict',\n",
       " 'strong',\n",
       " 'sales',\n",
       " ',',\n",
       " 'but',\n",
       " 'some',\n",
       " 'investors',\n",
       " 'are',\n",
       " 'worried',\n",
       " 'about',\n",
       " 'the',\n",
       " 'company',\n",
       " \"'\",\n",
       " 's',\n",
       " 'high',\n",
       " 'debt',\n",
       " 'load',\n",
       " '.']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "tokenizer(\"Analysts predict strong sales, but some investors are worried about the company's high debt load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Analysts',\n",
       " 'predict',\n",
       " 'strong',\n",
       " 'sales',\n",
       " ',',\n",
       " 'but',\n",
       " 'some',\n",
       " 'investors',\n",
       " 'are',\n",
       " 'worried',\n",
       " 'about',\n",
       " 'the',\n",
       " 'company',\n",
       " \"'s\",\n",
       " 'high',\n",
       " 'debt',\n",
       " 'load',\n",
       " '.']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('spacy')\n",
    "tokenizer(\"Analysts predict strong sales, but some investors are worried about the company's high debt load.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出使用 get_tokenizer('basic_english') 會只把單詞和標點符號分割開，而使用 get_tokenizer('spacy') 則會更詳細地分割，包括各種詞類和標點符號。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⟨pad⟩是用來填充句子長度的，因為每個句子長度不一樣，所以當你處理資料時為了讓他們長度一樣，需要將不夠長的句子補上⟨pad⟩。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⟨unk⟩是用在當vocab沒看過的字時，會將它視為⟨unk⟩。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我使用basic_english當作我的tokenizer，因為此次作業資料相對簡單，不複雜，所以不需要使用額外的tokenizer。我在collate_fn處理文字長度不一問題，torch.nn.utils.rnn.pad_sequence會將每個batch的文字自動補到最長的文字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "dataset=Dataset()\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "myvocab = build_vocab_from_iterator(yield_tokens(dataset), specials=[\"<pad>\",\"<unk>\",])\n",
    "myvocab.set_default_index(myvocab[\"<unk>\"])\n",
    "\n",
    "glove_vectors = torchtext.vocab.GloVe(name='6B',dim=100)\n",
    "embedding_matrix=torch.stack([glove_vectors.get_vecs_by_tokens(myvocab.get_itos()) ]).squeeze(0)\n",
    "# embedding_matrix = glove_vectors.vectors\n",
    "# embedding_matrix = torch.cat([torch.zeros(2, 100), embedding_matrix])\n",
    "\n",
    "# myvocab = torchtext.vocab.vocab(glove_vectors.stoi, min_freq = 0,specials=[\"<pad>\",\"<unk>\"])\n",
    "# myvocab.set_default_index(myvocab[\"<unk>\"])\n",
    "# ret = vec.get_vecs_by_tokens(examples, lower_case_backup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    #batch:[(label,text),...]\n",
    "    #return:label(b,),text(b,seq_lenth) \n",
    "    \n",
    "    labels,texts = zip(*batch)\n",
    "\n",
    "    text_tensors = []\n",
    "    for text in texts:\n",
    "        text_tensor = torch.tensor(myvocab(tokenizer(text)), dtype=torch.int)\n",
    "    \n",
    "        text_tensors.append(text_tensor)\n",
    "\n",
    "    \n",
    "    text_tensors = torch.nn.utils.rnn.pad_sequence(text_tensors, batch_first=True)\n",
    "\n",
    "    \n",
    "    label_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return label_tensor, text_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset=Dataset()\n",
    "\n",
    "train_size = int(0.8* len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "traindataset, valdataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "traindataloader = DataLoader(traindataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
    "valdataloader = DataLoader(valdataset, batch_size=32, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我的Transformer超參數為:d_model=100, nhead=4, d_hid=200 , nlayers=2, dropout=0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_model代表模型的輸入的特徵的尺寸，因為越大模型也越大且模型能夠更好地捕捉序列中的關係，但是模型的計算量和內存需求也會增加，所以我選擇100。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nhead是用來控制注意力機制中頭數的超參數，數值越大可以提高模型的表現，因為它可以更好地捕捉不同位置之間的依賴關係，但是也有可能造成overfitting，此數值的選擇我是以實驗慢慢進行調整。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_hid也就是Transformer裡面linear layer的維度，大小與訓練資料大小和複雜度有關，此數值選擇也是透過經驗法則，實驗中慢慢進行調整，直到選擇到滿意的參數。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nlayers代表總共有幾層Transformer，越多層，模型需要做的運算也越多，但是訓練資料如果很簡單，需要的層數也就沒必要太多，避免出現overfitting現象，此參數我選擇2，是因為我認為此次訓練資料不算太複雜，層數也不需太多。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout可以避免overfitting現象，我選擇0.1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    'd_model':100,\n",
    "    'nhead':4,\n",
    "    'd_hid':200,\n",
    "    'dropout':0.1,\n",
    "    'num_layers':2,\n",
    "    'epochs':200,\n",
    "    'lr':5e-4,\n",
    "    'wd':1e-4,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model,dropout,nhead,dim_hid, num_layers,vocab_size,num_class):\n",
    "        super(Transformer, self).__init__()\n",
    "        #nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)\n",
    "        self.emb=nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        self.pos_encoder = PositionalEncoding(d_model=d_model, dropout=dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model=d_model, nhead=nhead,\\\n",
    "                                                  dim_feedforward=dim_hid, dropout=dropout,batch_first=True,activation=F.silu)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(d_model,num_class),\n",
    "        )\n",
    "        \n",
    "        self.d_model = d_model\n",
    "    def forward(self, text):\n",
    "        \n",
    "        text=self.emb(text)#* math.sqrt(self.d_model) #8xntokenxd_model\n",
    "        text=torch.transpose(text, 0, 1)\n",
    "        text=self.pos_encoder(text)\n",
    "        text=torch.transpose(text, 0, 1)\n",
    "        text=self.transformer_encoder(text)\n",
    "        \n",
    "        text=torch.mean(text,dim=1)\n",
    "       \n",
    "        text=self.fc(text)\n",
    "        \n",
    "        return text\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(myvocab)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(d_model=config['d_model']\\\n",
    "    ,dropout=config['dropout'],nhead=config['nhead'],dim_hid=config['d_hid']\\\n",
    "        ,num_layers=config['num_layers'],vocab_size=vocab_size, num_class=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'],weight_decay=config['wd'])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, config['epochs'], eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  model.train()\n",
    "  acc_list=[]\n",
    "  loss_list=[]\n",
    "  for label,text  in (bar:=tqdm(traindataloader,ncols=0)):\n",
    "      optimizer.zero_grad()\n",
    "      #print('text',text.shape)\n",
    "      text=text.to(device)\n",
    "      label=label.to(device)\n",
    "      predicted_label = model(text)\n",
    "      \n",
    "      loss = criterion(predicted_label, label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      acc = (predicted_label.argmax(1) == label).sum().item()/label.shape[0]\n",
    "      #print(acc)\n",
    "      acc_list.append(acc)\n",
    "      loss_list.append(loss.item())\n",
    "      bar.set_description(f\"epochs[{epoch+1}/{config['epochs']}]|training\")\n",
    "      bar.set_postfix({'loss ': '{:.4f}'.format(sum(loss_list)/len(loss_list)),\n",
    "            'acc': '{:.4f}'.format(sum(acc_list)/len(acc_list))\n",
    "    })\n",
    "  scheduler.step()\n",
    "  #return sum(acc_list)/len(acc_list)\n",
    "def val():\n",
    "  model.eval()\n",
    "  acc_list=[]\n",
    "  with torch.no_grad():\n",
    "    for label,text  in (bar:=tqdm(valdataloader,ncols=0)):\n",
    "        \n",
    "        text=text.to(device)\n",
    "        label=label.to(device)\n",
    "        predicted_label = model(text)\n",
    "        \n",
    "        acc = (predicted_label.argmax(1) == label).sum().item()/label.shape[0]\n",
    "        \n",
    "        acc_list.append(acc)\n",
    "        \n",
    "        bar.set_description(f\"validation\")\n",
    "        bar.set_postfix({'acc': '{:.4f}'.format(sum(acc_list)/len(acc_list))})\n",
    "  \n",
    "  return sum(acc_list)/len(acc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs[1/200]|training: 100% 50/50 [00:00<00:00, 114.91it/s, loss =1.2571, acc=0.4075]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.59it/s, acc=0.6635]\n",
      "epochs[2/200]|training: 100% 50/50 [00:00<00:00, 127.99it/s, loss =0.7445, acc=0.6850]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.88it/s, acc=0.7933]\n",
      "epochs[3/200]|training: 100% 50/50 [00:00<00:00, 114.37it/s, loss =0.5090, acc=0.8075]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.54it/s, acc=0.8245]\n",
      "epochs[4/200]|training: 100% 50/50 [00:00<00:00, 127.19it/s, loss =0.4191, acc=0.8438]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.47it/s, acc=0.8630]\n",
      "epochs[5/200]|training: 100% 50/50 [00:00<00:00, 128.07it/s, loss =0.3598, acc=0.8694]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.82it/s, acc=0.8678]\n",
      "epochs[6/200]|training: 100% 50/50 [00:00<00:00, 126.43it/s, loss =0.2848, acc=0.9012]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.10it/s, acc=0.8822]\n",
      "epochs[7/200]|training: 100% 50/50 [00:00<00:00, 119.34it/s, loss =0.2551, acc=0.9125]\n",
      "validation: 100% 13/13 [00:00<00:00, 227.81it/s, acc=0.8582]\n",
      "epochs[8/200]|training: 100% 50/50 [00:00<00:00, 124.38it/s, loss =0.2287, acc=0.9187]\n",
      "validation: 100% 13/13 [00:00<00:00, 227.69it/s, acc=0.8798]\n",
      "epochs[9/200]|training: 100% 50/50 [00:00<00:00, 125.96it/s, loss =0.2014, acc=0.9275]\n",
      "validation: 100% 13/13 [00:00<00:00, 226.94it/s, acc=0.8438]\n",
      "epochs[10/200]|training: 100% 50/50 [00:00<00:00, 126.75it/s, loss =0.1708, acc=0.9400]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.25it/s, acc=0.8750]\n",
      "epochs[11/200]|training: 100% 50/50 [00:00<00:00, 127.31it/s, loss =0.1435, acc=0.9494]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.08it/s, acc=0.8486]\n",
      "epochs[12/200]|training: 100% 50/50 [00:00<00:00, 126.43it/s, loss =0.1445, acc=0.9494]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.86it/s, acc=0.8245]\n",
      "epochs[13/200]|training: 100% 50/50 [00:00<00:00, 125.50it/s, loss =0.1111, acc=0.9688]\n",
      "validation: 100% 13/13 [00:00<00:00, 228.64it/s, acc=0.8606]\n",
      "epochs[14/200]|training: 100% 50/50 [00:00<00:00, 125.60it/s, loss =0.0918, acc=0.9644]\n",
      "validation: 100% 13/13 [00:00<00:00, 225.90it/s, acc=0.8654]\n",
      "epochs[15/200]|training: 100% 50/50 [00:00<00:00, 125.09it/s, loss =0.0897, acc=0.9650]\n",
      "validation: 100% 13/13 [00:00<00:00, 225.79it/s, acc=0.8726]\n",
      "epochs[16/200]|training: 100% 50/50 [00:00<00:00, 123.99it/s, loss =0.0595, acc=0.9825]\n",
      "validation: 100% 13/13 [00:00<00:00, 224.30it/s, acc=0.8678]\n",
      "epochs[17/200]|training: 100% 50/50 [00:00<00:00, 124.97it/s, loss =0.0661, acc=0.9775]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.47it/s, acc=0.8774]\n",
      "epochs[18/200]|training: 100% 50/50 [00:00<00:00, 125.15it/s, loss =0.0740, acc=0.9731]\n",
      "validation: 100% 13/13 [00:00<00:00, 227.98it/s, acc=0.8726]\n",
      "epochs[19/200]|training: 100% 50/50 [00:00<00:00, 125.72it/s, loss =0.0419, acc=0.9850]\n",
      "validation: 100% 13/13 [00:00<00:00, 227.07it/s, acc=0.8582]\n",
      "epochs[20/200]|training: 100% 50/50 [00:00<00:00, 126.19it/s, loss =0.0287, acc=0.9944]\n",
      "validation: 100% 13/13 [00:00<00:00, 224.78it/s, acc=0.8726]\n",
      "epochs[21/200]|training: 100% 50/50 [00:00<00:00, 125.87it/s, loss =0.0320, acc=0.9875]\n",
      "validation: 100% 13/13 [00:00<00:00, 222.68it/s, acc=0.8630]\n",
      "epochs[22/200]|training: 100% 50/50 [00:00<00:00, 125.85it/s, loss =0.0410, acc=0.9844]\n",
      "validation: 100% 13/13 [00:00<00:00, 228.14it/s, acc=0.8678]\n",
      "epochs[23/200]|training: 100% 50/50 [00:00<00:00, 124.57it/s, loss =0.0525, acc=0.9825]\n",
      "validation: 100% 13/13 [00:00<00:00, 221.90it/s, acc=0.8630]\n",
      "epochs[24/200]|training: 100% 50/50 [00:00<00:00, 123.42it/s, loss =0.0364, acc=0.9869]\n",
      "validation: 100% 13/13 [00:00<00:00, 219.71it/s, acc=0.8630]\n",
      "epochs[25/200]|training: 100% 50/50 [00:00<00:00, 124.51it/s, loss =0.0322, acc=0.9900]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.88it/s, acc=0.8702]\n",
      "epochs[26/200]|training: 100% 50/50 [00:00<00:00, 128.01it/s, loss =0.0196, acc=0.9919]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.95it/s, acc=0.8606]\n",
      "epochs[27/200]|training: 100% 50/50 [00:00<00:00, 128.22it/s, loss =0.0155, acc=0.9956]\n",
      "validation: 100% 13/13 [00:00<00:00, 234.11it/s, acc=0.8678]\n",
      "epochs[28/200]|training: 100% 50/50 [00:00<00:00, 125.62it/s, loss =0.0223, acc=0.9912]\n",
      "validation: 100% 13/13 [00:00<00:00, 227.45it/s, acc=0.8654]\n",
      "epochs[29/200]|training: 100% 50/50 [00:00<00:00, 125.59it/s, loss =0.0238, acc=0.9912]\n",
      "validation: 100% 13/13 [00:00<00:00, 228.79it/s, acc=0.8798]\n",
      "epochs[30/200]|training: 100% 50/50 [00:00<00:00, 125.83it/s, loss =0.0118, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 229.09it/s, acc=0.8630]\n",
      "epochs[31/200]|training: 100% 50/50 [00:00<00:00, 125.42it/s, loss =0.0184, acc=0.9944]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.12it/s, acc=0.8630]\n",
      "epochs[32/200]|training: 100% 50/50 [00:00<00:00, 126.25it/s, loss =0.0062, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 225.26it/s, acc=0.8678]\n",
      "epochs[33/200]|training: 100% 50/50 [00:00<00:00, 125.98it/s, loss =0.0144, acc=0.9950]\n",
      "validation: 100% 13/13 [00:00<00:00, 221.55it/s, acc=0.8678]\n",
      "epochs[34/200]|training: 100% 50/50 [00:00<00:00, 123.74it/s, loss =0.0207, acc=0.9931]\n",
      "validation: 100% 13/13 [00:00<00:00, 228.40it/s, acc=0.8654]\n",
      "epochs[35/200]|training: 100% 50/50 [00:00<00:00, 124.82it/s, loss =0.0117, acc=0.9969]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.00it/s, acc=0.8726]\n",
      "epochs[36/200]|training: 100% 50/50 [00:00<00:00, 125.83it/s, loss =0.0139, acc=0.9950]\n",
      "validation: 100% 13/13 [00:00<00:00, 232.05it/s, acc=0.8750]\n",
      "epochs[37/200]|training: 100% 50/50 [00:00<00:00, 125.58it/s, loss =0.0124, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 233.09it/s, acc=0.8389]\n",
      "epochs[38/200]|training: 100% 50/50 [00:00<00:00, 123.30it/s, loss =0.0099, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 234.62it/s, acc=0.8630]\n",
      "epochs[39/200]|training: 100% 50/50 [00:00<00:00, 125.46it/s, loss =0.0110, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 232.07it/s, acc=0.8726]\n",
      "epochs[40/200]|training: 100% 50/50 [00:00<00:00, 126.04it/s, loss =0.0052, acc=0.9975]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.24it/s, acc=0.8582]\n",
      "epochs[41/200]|training: 100% 50/50 [00:00<00:00, 125.73it/s, loss =0.0201, acc=0.9906]\n",
      "validation: 100% 13/13 [00:00<00:00, 232.14it/s, acc=0.8678]\n",
      "epochs[42/200]|training: 100% 50/50 [00:00<00:00, 125.94it/s, loss =0.0100, acc=0.9969]\n",
      "validation: 100% 13/13 [00:00<00:00, 233.57it/s, acc=0.8702]\n",
      "epochs[43/200]|training: 100% 50/50 [00:00<00:00, 125.71it/s, loss =0.0116, acc=0.9950]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.47it/s, acc=0.8678]\n",
      "epochs[44/200]|training: 100% 50/50 [00:00<00:00, 125.44it/s, loss =0.0104, acc=0.9975]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.86it/s, acc=0.8413]\n",
      "epochs[45/200]|training: 100% 50/50 [00:00<00:00, 123.85it/s, loss =0.0095, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.71it/s, acc=0.8606]\n",
      "epochs[46/200]|training: 100% 50/50 [00:00<00:00, 127.91it/s, loss =0.0106, acc=0.9956]\n",
      "validation: 100% 13/13 [00:00<00:00, 239.49it/s, acc=0.8606]\n",
      "epochs[47/200]|training: 100% 50/50 [00:00<00:00, 128.45it/s, loss =0.0017, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.89it/s, acc=0.8726]\n",
      "epochs[48/200]|training: 100% 50/50 [00:00<00:00, 128.65it/s, loss =0.0072, acc=0.9975]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.36it/s, acc=0.8702]\n",
      "epochs[49/200]|training: 100% 50/50 [00:00<00:00, 127.81it/s, loss =0.0163, acc=0.9950]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.86it/s, acc=0.8678]\n",
      "epochs[50/200]|training: 100% 50/50 [00:00<00:00, 126.10it/s, loss =0.0200, acc=0.9938]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.80it/s, acc=0.8606]\n",
      "epochs[51/200]|training: 100% 50/50 [00:00<00:00, 126.61it/s, loss =0.0061, acc=0.9969]\n",
      "validation: 100% 13/13 [00:00<00:00, 234.89it/s, acc=0.8702]\n",
      "epochs[52/200]|training: 100% 50/50 [00:00<00:00, 124.05it/s, loss =0.0121, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.66it/s, acc=0.8534]\n",
      "epochs[53/200]|training: 100% 50/50 [00:00<00:00, 125.54it/s, loss =0.0096, acc=0.9956]\n",
      "validation: 100% 13/13 [00:00<00:00, 234.30it/s, acc=0.8438]\n",
      "epochs[54/200]|training: 100% 50/50 [00:00<00:00, 124.29it/s, loss =0.0121, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.91it/s, acc=0.8582]\n",
      "epochs[55/200]|training: 100% 50/50 [00:00<00:00, 123.28it/s, loss =0.0106, acc=0.9956]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.88it/s, acc=0.8534]\n",
      "epochs[56/200]|training: 100% 50/50 [00:00<00:00, 125.79it/s, loss =0.0105, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.59it/s, acc=0.8582]\n",
      "epochs[57/200]|training: 100% 50/50 [00:00<00:00, 124.74it/s, loss =0.0026, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.74it/s, acc=0.8606]\n",
      "epochs[58/200]|training: 100% 50/50 [00:00<00:00, 125.78it/s, loss =0.0110, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.64it/s, acc=0.8726]\n",
      "epochs[59/200]|training: 100% 50/50 [00:00<00:00, 125.43it/s, loss =0.0032, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.73it/s, acc=0.8606]\n",
      "epochs[60/200]|training: 100% 50/50 [00:00<00:00, 125.98it/s, loss =0.0050, acc=0.9975]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.49it/s, acc=0.8702]\n",
      "epochs[61/200]|training: 100% 50/50 [00:00<00:00, 124.53it/s, loss =0.0071, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 229.17it/s, acc=0.8606]\n",
      "epochs[62/200]|training: 100% 50/50 [00:00<00:00, 124.24it/s, loss =0.0015, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.05it/s, acc=0.8606]\n",
      "epochs[63/200]|training: 100% 50/50 [00:00<00:00, 112.69it/s, loss =0.0061, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.13it/s, acc=0.8389]\n",
      "epochs[64/200]|training: 100% 50/50 [00:00<00:00, 111.66it/s, loss =0.0123, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.92it/s, acc=0.8630]\n",
      "epochs[65/200]|training: 100% 50/50 [00:00<00:00, 112.18it/s, loss =0.0183, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.30it/s, acc=0.8774]\n",
      "epochs[66/200]|training: 100% 50/50 [00:00<00:00, 111.49it/s, loss =0.0061, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.03it/s, acc=0.8774]\n",
      "epochs[67/200]|training: 100% 50/50 [00:00<00:00, 111.28it/s, loss =0.0057, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.15it/s, acc=0.8486]\n",
      "epochs[68/200]|training: 100% 50/50 [00:00<00:00, 111.85it/s, loss =0.0046, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.52it/s, acc=0.8534]\n",
      "epochs[69/200]|training: 100% 50/50 [00:00<00:00, 111.56it/s, loss =0.0044, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.03it/s, acc=0.8774]\n",
      "epochs[70/200]|training: 100% 50/50 [00:00<00:00, 111.43it/s, loss =0.0092, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.94it/s, acc=0.8582]\n",
      "epochs[71/200]|training: 100% 50/50 [00:00<00:00, 111.44it/s, loss =0.0110, acc=0.9969]\n",
      "validation: 100% 13/13 [00:00<00:00, 233.99it/s, acc=0.8678]\n",
      "epochs[72/200]|training: 100% 50/50 [00:00<00:00, 111.43it/s, loss =0.0063, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.56it/s, acc=0.8630]\n",
      "epochs[73/200]|training: 100% 50/50 [00:00<00:00, 111.49it/s, loss =0.0014, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.75it/s, acc=0.8534]\n",
      "epochs[74/200]|training: 100% 50/50 [00:00<00:00, 111.61it/s, loss =0.0062, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.49it/s, acc=0.8702]\n",
      "epochs[75/200]|training: 100% 50/50 [00:00<00:00, 111.90it/s, loss =0.0029, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.01it/s, acc=0.8750]\n",
      "epochs[76/200]|training: 100% 50/50 [00:00<00:00, 111.58it/s, loss =0.0029, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.82it/s, acc=0.8654]\n",
      "epochs[77/200]|training: 100% 50/50 [00:00<00:00, 112.05it/s, loss =0.0056, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.28it/s, acc=0.8558]\n",
      "epochs[78/200]|training: 100% 50/50 [00:00<00:00, 111.38it/s, loss =0.0095, acc=0.9975]\n",
      "validation: 100% 13/13 [00:00<00:00, 233.01it/s, acc=0.8630]\n",
      "epochs[79/200]|training: 100% 50/50 [00:00<00:00, 111.38it/s, loss =0.0034, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.03it/s, acc=0.8630]\n",
      "epochs[80/200]|training: 100% 50/50 [00:00<00:00, 112.46it/s, loss =0.0028, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 229.04it/s, acc=0.8774]\n",
      "epochs[81/200]|training: 100% 50/50 [00:00<00:00, 111.80it/s, loss =0.0006, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.28it/s, acc=0.8702]\n",
      "epochs[82/200]|training: 100% 50/50 [00:00<00:00, 111.49it/s, loss =0.0063, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.33it/s, acc=0.8438]\n",
      "epochs[83/200]|training: 100% 50/50 [00:00<00:00, 120.23it/s, loss =0.0122, acc=0.9962]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.78it/s, acc=0.8558]\n",
      "epochs[84/200]|training: 100% 50/50 [00:00<00:00, 111.23it/s, loss =0.0090, acc=0.9975]\n",
      "validation: 100% 13/13 [00:00<00:00, 234.94it/s, acc=0.8630]\n",
      "epochs[85/200]|training: 100% 50/50 [00:00<00:00, 111.22it/s, loss =0.0013, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.20it/s, acc=0.8750]\n",
      "epochs[86/200]|training: 100% 50/50 [00:00<00:00, 111.83it/s, loss =0.0007, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.00it/s, acc=0.8750]\n",
      "epochs[87/200]|training: 100% 50/50 [00:00<00:00, 111.39it/s, loss =0.0023, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 213.59it/s, acc=0.8702]\n",
      "epochs[88/200]|training: 100% 50/50 [00:00<00:00, 111.77it/s, loss =0.0085, acc=0.9975]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.44it/s, acc=0.8606]\n",
      "epochs[89/200]|training: 100% 50/50 [00:00<00:00, 111.94it/s, loss =0.0061, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 239.21it/s, acc=0.8654]\n",
      "epochs[90/200]|training: 100% 50/50 [00:00<00:00, 111.99it/s, loss =0.0023, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.62it/s, acc=0.8726]\n",
      "epochs[91/200]|training: 100% 50/50 [00:00<00:00, 112.65it/s, loss =0.0011, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.66it/s, acc=0.8702]\n",
      "epochs[92/200]|training: 100% 50/50 [00:00<00:00, 111.83it/s, loss =0.0052, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.65it/s, acc=0.8630]\n",
      "epochs[93/200]|training: 100% 50/50 [00:00<00:00, 111.59it/s, loss =0.0018, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 239.22it/s, acc=0.8846]\n",
      "epochs[94/200]|training: 100% 50/50 [00:00<00:00, 106.76it/s, loss =0.0005, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.86it/s, acc=0.8678]\n",
      "epochs[95/200]|training: 100% 50/50 [00:00<00:00, 111.78it/s, loss =0.0073, acc=0.9969]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.41it/s, acc=0.8774]\n",
      "epochs[96/200]|training: 100% 50/50 [00:00<00:00, 111.79it/s, loss =0.0017, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 240.42it/s, acc=0.8774]\n",
      "epochs[97/200]|training: 100% 50/50 [00:00<00:00, 111.51it/s, loss =0.0009, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.44it/s, acc=0.8774]\n",
      "epochs[98/200]|training: 100% 50/50 [00:00<00:00, 111.21it/s, loss =0.0017, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.23it/s, acc=0.8822]\n",
      "epochs[99/200]|training: 100% 50/50 [00:00<00:00, 112.42it/s, loss =0.0072, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.45it/s, acc=0.8750]\n",
      "epochs[100/200]|training: 100% 50/50 [00:00<00:00, 111.11it/s, loss =0.0066, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.06it/s, acc=0.8678]\n",
      "epochs[101/200]|training: 100% 50/50 [00:00<00:00, 111.43it/s, loss =0.0051, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.66it/s, acc=0.8702]\n",
      "epochs[102/200]|training: 100% 50/50 [00:00<00:00, 111.96it/s, loss =0.0035, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 234.72it/s, acc=0.8846]\n",
      "epochs[103/200]|training: 100% 50/50 [00:00<00:00, 111.67it/s, loss =0.0019, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.57it/s, acc=0.8798]\n",
      "epochs[104/200]|training: 100% 50/50 [00:00<00:00, 110.98it/s, loss =0.0035, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.33it/s, acc=0.8726]\n",
      "epochs[105/200]|training: 100% 50/50 [00:00<00:00, 111.42it/s, loss =0.0004, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.37it/s, acc=0.8774]\n",
      "epochs[106/200]|training: 100% 50/50 [00:00<00:00, 111.56it/s, loss =0.0004, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.67it/s, acc=0.8798]\n",
      "epochs[107/200]|training: 100% 50/50 [00:00<00:00, 111.35it/s, loss =0.0027, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.73it/s, acc=0.8654]\n",
      "epochs[108/200]|training: 100% 50/50 [00:00<00:00, 111.42it/s, loss =0.0034, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.51it/s, acc=0.8702]\n",
      "epochs[109/200]|training: 100% 50/50 [00:00<00:00, 113.13it/s, loss =0.0003, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.42it/s, acc=0.8774]\n",
      "epochs[110/200]|training: 100% 50/50 [00:00<00:00, 114.07it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.74it/s, acc=0.8846]\n",
      "epochs[111/200]|training: 100% 50/50 [00:00<00:00, 112.11it/s, loss =0.0003, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.64it/s, acc=0.8726]\n",
      "epochs[112/200]|training: 100% 50/50 [00:00<00:00, 110.59it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.66it/s, acc=0.8822]\n",
      "epochs[113/200]|training: 100% 50/50 [00:00<00:00, 112.03it/s, loss =0.0050, acc=0.9975]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.46it/s, acc=0.8750]\n",
      "epochs[114/200]|training: 100% 50/50 [00:00<00:00, 113.59it/s, loss =0.0025, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.01it/s, acc=0.8558]\n",
      "epochs[115/200]|training: 100% 50/50 [00:00<00:00, 110.96it/s, loss =0.0039, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.59it/s, acc=0.8750]\n",
      "epochs[116/200]|training: 100% 50/50 [00:00<00:00, 111.25it/s, loss =0.0056, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.47it/s, acc=0.8750]\n",
      "epochs[117/200]|training: 100% 50/50 [00:00<00:00, 113.02it/s, loss =0.0006, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.85it/s, acc=0.8846]\n",
      "epochs[118/200]|training: 100% 50/50 [00:00<00:00, 113.19it/s, loss =0.0068, acc=0.9975]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.69it/s, acc=0.8630]\n",
      "epochs[119/200]|training: 100% 50/50 [00:00<00:00, 111.92it/s, loss =0.0043, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.40it/s, acc=0.8726]\n",
      "epochs[120/200]|training: 100% 50/50 [00:00<00:00, 111.71it/s, loss =0.0012, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.67it/s, acc=0.8606]\n",
      "epochs[121/200]|training: 100% 50/50 [00:00<00:00, 113.12it/s, loss =0.0008, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.40it/s, acc=0.8678]\n",
      "epochs[122/200]|training: 100% 50/50 [00:00<00:00, 111.64it/s, loss =0.0003, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.27it/s, acc=0.8726]\n",
      "epochs[123/200]|training: 100% 50/50 [00:00<00:00, 113.25it/s, loss =0.0005, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.04it/s, acc=0.8630]\n",
      "epochs[124/200]|training: 100% 50/50 [00:00<00:00, 125.93it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.45it/s, acc=0.8606]\n",
      "epochs[125/200]|training: 100% 50/50 [00:00<00:00, 127.78it/s, loss =0.0004, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.49it/s, acc=0.8678]\n",
      "epochs[126/200]|training: 100% 50/50 [00:00<00:00, 127.53it/s, loss =0.0013, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.66it/s, acc=0.8606]\n",
      "epochs[127/200]|training: 100% 50/50 [00:00<00:00, 127.11it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.85it/s, acc=0.8654]\n",
      "epochs[128/200]|training: 100% 50/50 [00:00<00:00, 126.25it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 232.23it/s, acc=0.8582]\n",
      "epochs[129/200]|training: 100% 50/50 [00:00<00:00, 125.59it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 233.66it/s, acc=0.8654]\n",
      "epochs[130/200]|training: 100% 50/50 [00:00<00:00, 126.66it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.07it/s, acc=0.8678]\n",
      "epochs[131/200]|training: 100% 50/50 [00:00<00:00, 127.24it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.57it/s, acc=0.8702]\n",
      "epochs[132/200]|training: 100% 50/50 [00:00<00:00, 125.97it/s, loss =0.0011, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 215.49it/s, acc=0.8726]\n",
      "epochs[133/200]|training: 100% 50/50 [00:00<00:00, 125.36it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 229.10it/s, acc=0.8654]\n",
      "epochs[134/200]|training: 100% 50/50 [00:00<00:00, 124.99it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.13it/s, acc=0.8726]\n",
      "epochs[135/200]|training: 100% 50/50 [00:00<00:00, 123.45it/s, loss =0.0011, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 228.10it/s, acc=0.8654]\n",
      "epochs[136/200]|training: 100% 50/50 [00:00<00:00, 124.30it/s, loss =0.0055, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 226.18it/s, acc=0.8678]\n",
      "epochs[137/200]|training: 100% 50/50 [00:00<00:00, 124.13it/s, loss =0.0007, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.74it/s, acc=0.8750]\n",
      "epochs[138/200]|training: 100% 50/50 [00:00<00:00, 124.63it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.65it/s, acc=0.8678]\n",
      "epochs[139/200]|training: 100% 50/50 [00:00<00:00, 125.27it/s, loss =0.0016, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 232.85it/s, acc=0.8702]\n",
      "epochs[140/200]|training: 100% 50/50 [00:00<00:00, 123.59it/s, loss =0.0011, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 225.44it/s, acc=0.8750]\n",
      "epochs[141/200]|training: 100% 50/50 [00:00<00:00, 124.31it/s, loss =0.0003, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 232.28it/s, acc=0.8654]\n",
      "epochs[142/200]|training: 100% 50/50 [00:00<00:00, 124.03it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.59it/s, acc=0.8630]\n",
      "epochs[143/200]|training: 100% 50/50 [00:00<00:00, 124.27it/s, loss =0.0004, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.98it/s, acc=0.8558]\n",
      "epochs[144/200]|training: 100% 50/50 [00:00<00:00, 124.84it/s, loss =0.0020, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.30it/s, acc=0.8702]\n",
      "epochs[145/200]|training: 100% 50/50 [00:00<00:00, 124.63it/s, loss =0.0032, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 227.68it/s, acc=0.8726]\n",
      "epochs[146/200]|training: 100% 50/50 [00:00<00:00, 124.76it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 227.62it/s, acc=0.8750]\n",
      "epochs[147/200]|training: 100% 50/50 [00:00<00:00, 125.07it/s, loss =0.0003, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.76it/s, acc=0.8678]\n",
      "epochs[148/200]|training: 100% 50/50 [00:00<00:00, 125.13it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.59it/s, acc=0.8750]\n",
      "epochs[149/200]|training: 100% 50/50 [00:00<00:00, 124.36it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.52it/s, acc=0.8750]\n",
      "epochs[150/200]|training: 100% 50/50 [00:00<00:00, 124.86it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.57it/s, acc=0.8678]\n",
      "epochs[151/200]|training: 100% 50/50 [00:00<00:00, 124.63it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 232.56it/s, acc=0.8726]\n",
      "epochs[152/200]|training: 100% 50/50 [00:00<00:00, 125.75it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 229.90it/s, acc=0.8726]\n",
      "epochs[153/200]|training: 100% 50/50 [00:00<00:00, 124.33it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 228.71it/s, acc=0.8678]\n",
      "epochs[154/200]|training: 100% 50/50 [00:00<00:00, 124.18it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 229.68it/s, acc=0.8702]\n",
      "epochs[155/200]|training: 100% 50/50 [00:00<00:00, 124.40it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.16it/s, acc=0.8702]\n",
      "epochs[156/200]|training: 100% 50/50 [00:00<00:00, 125.06it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.29it/s, acc=0.8774]\n",
      "epochs[157/200]|training: 100% 50/50 [00:00<00:00, 123.10it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.89it/s, acc=0.8726]\n",
      "epochs[158/200]|training: 100% 50/50 [00:00<00:00, 124.38it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 222.56it/s, acc=0.8702]\n",
      "epochs[159/200]|training: 100% 50/50 [00:00<00:00, 124.53it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 229.41it/s, acc=0.8726]\n",
      "epochs[160/200]|training: 100% 50/50 [00:00<00:00, 123.41it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 233.76it/s, acc=0.8726]\n",
      "epochs[161/200]|training: 100% 50/50 [00:00<00:00, 126.82it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.26it/s, acc=0.8750]\n",
      "epochs[162/200]|training: 100% 50/50 [00:00<00:00, 127.92it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.22it/s, acc=0.8774]\n",
      "epochs[163/200]|training: 100% 50/50 [00:00<00:00, 127.77it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.84it/s, acc=0.8606]\n",
      "epochs[164/200]|training: 100% 50/50 [00:00<00:00, 126.11it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.42it/s, acc=0.8702]\n",
      "epochs[165/200]|training: 100% 50/50 [00:00<00:00, 128.02it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.95it/s, acc=0.8630]\n",
      "epochs[166/200]|training: 100% 50/50 [00:00<00:00, 127.83it/s, loss =0.0017, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 236.10it/s, acc=0.8654]\n",
      "epochs[167/200]|training: 100% 50/50 [00:00<00:00, 128.28it/s, loss =0.0003, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.90it/s, acc=0.8606]\n",
      "epochs[168/200]|training: 100% 50/50 [00:00<00:00, 111.56it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 239.56it/s, acc=0.8702]\n",
      "epochs[169/200]|training: 100% 50/50 [00:00<00:00, 112.24it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 234.75it/s, acc=0.8678]\n",
      "epochs[170/200]|training: 100% 50/50 [00:00<00:00, 111.54it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.04it/s, acc=0.8798]\n",
      "epochs[171/200]|training: 100% 50/50 [00:00<00:00, 112.19it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 239.50it/s, acc=0.8774]\n",
      "epochs[172/200]|training: 100% 50/50 [00:00<00:00, 111.41it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 234.74it/s, acc=0.8702]\n",
      "epochs[173/200]|training: 100% 50/50 [00:00<00:00, 112.21it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.40it/s, acc=0.8750]\n",
      "epochs[174/200]|training: 100% 50/50 [00:00<00:00, 111.29it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 240.66it/s, acc=0.8654]\n",
      "epochs[175/200]|training: 100% 50/50 [00:00<00:00, 111.89it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 239.07it/s, acc=0.8702]\n",
      "epochs[176/200]|training: 100% 50/50 [00:00<00:00, 112.13it/s, loss =0.0000, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 239.52it/s, acc=0.8726]\n",
      "epochs[177/200]|training: 100% 50/50 [00:00<00:00, 112.12it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.36it/s, acc=0.8774]\n",
      "epochs[178/200]|training: 100% 50/50 [00:00<00:00, 111.58it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 240.16it/s, acc=0.8678]\n",
      "epochs[179/200]|training: 100% 50/50 [00:00<00:00, 111.09it/s, loss =0.0006, acc=0.9994]\n",
      "validation: 100% 13/13 [00:00<00:00, 237.53it/s, acc=0.8630]\n",
      "epochs[180/200]|training: 100% 50/50 [00:00<00:00, 111.48it/s, loss =0.0036, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.20it/s, acc=0.8678]\n",
      "epochs[181/200]|training: 100% 50/50 [00:00<00:00, 112.32it/s, loss =0.0057, acc=0.9981]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.51it/s, acc=0.8726]\n",
      "epochs[182/200]|training: 100% 50/50 [00:00<00:00, 126.41it/s, loss =0.0007, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 232.31it/s, acc=0.8750]\n",
      "epochs[183/200]|training: 100% 50/50 [00:00<00:00, 126.38it/s, loss =0.0003, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 222.48it/s, acc=0.8702]\n",
      "epochs[184/200]|training: 100% 50/50 [00:00<00:00, 126.67it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.82it/s, acc=0.8774]\n",
      "epochs[185/200]|training: 100% 50/50 [00:00<00:00, 126.55it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.77it/s, acc=0.8630]\n",
      "epochs[186/200]|training: 100% 50/50 [00:00<00:00, 126.57it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.47it/s, acc=0.8774]\n",
      "epochs[187/200]|training: 100% 50/50 [00:00<00:00, 126.53it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 232.08it/s, acc=0.8774]\n",
      "epochs[188/200]|training: 100% 50/50 [00:00<00:00, 126.12it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.71it/s, acc=0.8702]\n",
      "epochs[189/200]|training: 100% 50/50 [00:00<00:00, 126.21it/s, loss =0.0032, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.06it/s, acc=0.8678]\n",
      "epochs[190/200]|training: 100% 50/50 [00:00<00:00, 126.08it/s, loss =0.0005, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.93it/s, acc=0.8750]\n",
      "epochs[191/200]|training: 100% 50/50 [00:00<00:00, 124.58it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 230.44it/s, acc=0.8678]\n",
      "epochs[192/200]|training: 100% 50/50 [00:00<00:00, 124.68it/s, loss =0.0002, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 227.59it/s, acc=0.8702]\n",
      "epochs[193/200]|training: 100% 50/50 [00:00<00:00, 124.94it/s, loss =0.0004, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 228.06it/s, acc=0.8726]\n",
      "epochs[194/200]|training: 100% 50/50 [00:00<00:00, 124.33it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 226.84it/s, acc=0.8774]\n",
      "epochs[195/200]|training: 100% 50/50 [00:00<00:00, 127.08it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.80it/s, acc=0.8750]\n",
      "epochs[196/200]|training: 100% 50/50 [00:00<00:00, 128.11it/s, loss =0.0019, acc=0.9988]\n",
      "validation: 100% 13/13 [00:00<00:00, 235.50it/s, acc=0.8846]\n",
      "epochs[197/200]|training: 100% 50/50 [00:00<00:00, 127.35it/s, loss =0.0004, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 231.51it/s, acc=0.8702]\n",
      "epochs[198/200]|training: 100% 50/50 [00:00<00:00, 125.47it/s, loss =0.0003, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.72it/s, acc=0.8750]\n",
      "epochs[199/200]|training: 100% 50/50 [00:00<00:00, 127.81it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 239.50it/s, acc=0.8678]\n",
      "epochs[200/200]|training: 100% 50/50 [00:00<00:00, 128.00it/s, loss =0.0001, acc=1.0000]\n",
      "validation: 100% 13/13 [00:00<00:00, 238.21it/s, acc=0.8702]\n"
     ]
    }
   ],
   "source": [
    "best_acc=0.7\n",
    "for epoch in range(config['epochs']):\n",
    "  train(epoch)\n",
    "  acc=val()\n",
    "  if acc>best_acc:\n",
    "      torch.save(model.state_dict(), 'best.pt')\n",
    "      best_acc=acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846153846153846"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset=TestDataset()\n",
    "testdataloader = DataLoader(testdataset, batch_size=1, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "  model.eval()\n",
    "  predict=[]\n",
    "  with torch.no_grad():\n",
    "    for no_use,text  in (bar:=tqdm(testdataloader)):\n",
    "      \n",
    "      text=text.cpu()#.to(device)\n",
    "      predicted_label = model(text)\n",
    "      # print(predicted_label.shape)\n",
    "      output=predicted_label.argmax(1).cpu().numpy()\n",
    "      # print(output)\n",
    "      predict.extend(output)\n",
    "    \n",
    "  return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(myvocab)\n",
    "model = Transformer(d_model=config['d_model']\\\n",
    "    ,dropout=config['dropout'],nhead=config['nhead'],dim_hid=config['d_hid']\\\n",
    "        ,num_layers=config['num_layers'],vocab_size=vocab_size, num_class=4).cpu()#\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('best.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 1262.89it/s]\n"
     ]
    }
   ],
   "source": [
    "predict=test(model)\n",
    "\n",
    "data = [(i+1, val+1) for i, val in enumerate(predict)]\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['id', 'category'])  \n",
    "    writer.writerows(data)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
